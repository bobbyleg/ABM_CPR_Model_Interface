{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract = \"\"\"Abstract of the paper \\n \n",
    "The skewed degree distributions observed in social networks creates a bistable common pool resource outcomes with\n",
    "significant dispersion when individuals are encouraged to choose extraction behaviors diverging from the majority. \\n \n",
    "An abundant resource outcome emerges when the hubs do not limit their extraction, creating an incentive for the predominant\n",
    "share of individuals preserve the resource. On the contrary, scarce resource outcome arise if the hubs limit their extraction, \n",
    "encouraging others to extract with high effort. The full-information equilibrium lies between these outcomes. \\n \n",
    "As the skewness of the degree distribution increases, (i) the group of individuals with few connections increases, and \n",
    "(ii) individuals within this group have access to less information. As a result, the majority illusion and the dispersion between\n",
    "the abundant and scarce outcomes intensify. \\n \n",
    "Common pool resource users with significant visibility plausibily exert concomitant environmental impact.\n",
    "Consequently, we adapt the model with a degree-dependency factor (DDF) that allocates a greater environmental weight to \n",
    "highly-connected individuals. The DDF aligns hubs' environmental impact with their visibility, mitigating the majority illusion.\n",
    "Raising the DDF diminishes the dispersion between the abundant and scarce resource outcomes,\n",
    "uniting them with the FIE when the DDF reaches a critical value.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_explanation = \"\"\"Welcome to the Agent-Based Common Pool Resource model! \\n \n",
    "The inputs consist of three components. \n",
    "On the right, you can select which graphs the model should output. The big frame in the model comprises five \n",
    "tabs for different types of input parameters (e.g., number of simulations, network settings, etc.). \n",
    "Note that sliders relating to integer values, like the number of simulations, are rounded down.\n",
    "In the bottom, you can type in your preferred plot titles, for example to help remind you which inputs \n",
    "you selected and organize your results. Be sure to press enter after typing in your plot title. \\n \n",
    "Finally, when you're ready, press 'Run model' to get your output. For more information, visit the GitHub page. \\n \n",
    "In the following, you can find a description of the model paramaters. \\n \n",
    "In the General tab, the paramaters Simulations, Generations, and Agents determine the number of times the model is \n",
    "run, for how many generations, and with how many agents. The parameter \\u03B5 is the relative speed of strategic and\n",
    "environmental dynamics. Higher values of \\u03B5 effectively provides agents with less time to respond to changing environmental conditions. \\n \n",
    "In the Initialization tab, the values of Resource and  Low effort fraction determine the initial values of the environment\n",
    "and the fraction of agents extracting with low effort. \\n \n",
    "In the Incentives tab, the parameters \\u03C1, \\u03B31L, \\u03B32L, \\u03B33L, \\u03B31H, \\u03B32H and \\u03B33H govern the model's incentive structure.\n",
    "The parameters with an H in the name and the parameter \\u03C1 relate to the payoff of extracting with high effort,\n",
    "while the paramater with an L relate to the payoff of extracting with low effort.\n",
    "Most significant are the differences between these parameters.\n",
    "The difference between \\u03B31H and \\u03B31L governs whether agents want to go with or against the majority.\n",
    "When \\u03B31H < \\u03B31L, there is an incentive to go with the majority. \n",
    "This incentive is modified by the difference between \\u03B32H and \\u03B33H.\n",
    "Values of \\u03B31H above \\u03B31L intensify the incentive to with the majority.\n",
    "The difference between \\u03B32H and \\u03B32L shape how agents respond to the state of the environment.\n",
    "Typically, \\u03B32H > \\u03B32L. The larger the difference, the more agents care about the environment\n",
    "Positive values of the parameter \\u03C1 make extracting with high effort more attractive. \\n \n",
    "In the Network tab, you can select whether the information-sharing network between agents should be constructed  \n",
    "using the Erdös-Rényi algorithm or the Barabasi-Albert algorithm. When using the Erdös-Rényi algorithm, the link \n",
    "density can be chosen. When using the Barabasi-Albert algorithm, the number of new links added whenever a new node is added to the network can be chosen. \\n \n",
    "In the Heuristics Switching Model (HSM) tab, you may alter the values of the \\u03B21, \\u03B22, \\u03B23, \\u03C1, \\u03B7, and \\u03C6 parameters.\n",
    "The parameter \\u03B21 is used in the adaptive expections rule, \\u03B22 in the contrarian rule and \\u03B23 in the trend-following rule.\n",
    "\\u03C1 governs the probability an agent chooses a new heuristic within a given round, \\u03B7 how well agents remember the past\n",
    "performance of heuristics, and \\u03C6 the choice intensity, i.e., how quick agents are to choose better-performing rules.\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
